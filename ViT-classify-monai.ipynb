{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcc27a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: monai==1.3.0 in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from monai==1.3.0) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.9 in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from monai==1.3.0) (2.5.1)\n",
      "Requirement already satisfied: filelock in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from torch>=1.9->monai==1.3.0) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from torch>=1.9->monai==1.3.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from torch>=1.9->monai==1.3.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from torch>=1.9->monai==1.3.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from torch>=1.9->monai==1.3.0) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from torch>=1.9->monai==1.3.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from torch>=1.9->monai==1.3.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from torch>=1.9->monai==1.3.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from torch>=1.9->monai==1.3.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from torch>=1.9->monai==1.3.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from torch>=1.9->monai==1.3.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from torch>=1.9->monai==1.3.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from torch>=1.9->monai==1.3.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from torch>=1.9->monai==1.3.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from torch>=1.9->monai==1.3.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from torch>=1.9->monai==1.3.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from torch>=1.9->monai==1.3.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from torch>=1.9->monai==1.3.0) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from torch>=1.9->monai==1.3.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.9->monai==1.3.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr4/ec523/baxline/.local/lib/python3.10/site-packages (from jinja2->torch>=1.9->monai==1.3.0) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install monai==1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f83b6cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr4/ec523/baxline/.local/lib/python3.10/site-packages/ignite/handlers/checkpoint.py:17: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import monai\n",
    "print(monai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c4c64e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import monai\n",
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImageD, EnsureChannelFirstD, SpacingD, OrientationD, ScaleIntensityD,\n",
    "    ToTensorD, RandFlipD, RandRotateD, RandZoomD, EnsureTypeD\n",
    ")\n",
    "from monai.networks.nets import ViT\n",
    "# from monai.metrics import Accuracy\n",
    "from torchmetrics.classification import Accuracy\n",
    "from monai.metrics import compute_confusion_matrix_metric\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm\n",
    "from monai.transforms import Resized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0ef8629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_label(label_path):\n",
    "    \"\"\"\n",
    "    Load the label CSV file and determine the correct label.\n",
    "    If no hemorrhage is present, return 'no_hemorrhage'.\n",
    "    If a hemorrhage is present, return the most specific hemorrhage type.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        label_df = pd.read_csv(label_path)\n",
    "        label_df.columns = label_df.columns.str.strip()  # Clean column names\n",
    "        label_df[\"label\"] = pd.to_numeric(label_df[\"label\"], errors=\"coerce\").fillna(0).astype(int)  # Ensure labels are integers\n",
    "        \n",
    "        # Validate required columns exist\n",
    "        if \"hemorrhage_type\" not in label_df.columns or \"label\" not in label_df.columns:\n",
    "            print(f\"Malformed CSV, missing columns: {label_path}\")\n",
    "            return None\n",
    "\n",
    "        # Check for specific hemorrhage types\n",
    "        specific_hemorrhage = label_df[(label_df[\"label\"] == 1) & (label_df[\"hemorrhage_type\"] != \"any\")]\n",
    "        if not specific_hemorrhage.empty:\n",
    "            return specific_hemorrhage[\"hemorrhage_type\"].iloc[0]  # Return first specific hemorrhage type\n",
    "\n",
    "        # Check for 'any'\n",
    "        if \"any\" in label_df[\"hemorrhage_type\"].values:\n",
    "            any_label = label_df.loc[label_df[\"hemorrhage_type\"] == \"any\", \"label\"].iloc[0]\n",
    "            if any_label == 1:\n",
    "                return \"any\"\n",
    "\n",
    "        # No hemorrhage\n",
    "        return \"no_hemorrhage\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {label_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2edd6dc",
   "metadata": {},
   "source": [
    "# creating dictionary - only run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73914ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing NIfTI or CSV file in folder: /projectnb/ec523kb/projects/hemorrhage-classification/stage_2_train_sorted_nifti_pruned/ID_863be16ddb\n",
      "Total valid files: 3783\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from monai.transforms import LoadImage\n",
    "\n",
    "# Map hemorrhage types to integers\n",
    "hemorrhage_types = {\n",
    "    \"intraparenchymal\": 0,\n",
    "    \"intraventricular\": 1,\n",
    "    \"subarachnoid\": 2,\n",
    "    \"subdural\": 3,\n",
    "    \"epidural\": 4,\n",
    "    \"any\": 5  # Add 'any' for completeness\n",
    "}\n",
    "\n",
    "# Root data directory\n",
    "data_root = \"/projectnb/ec523kb/projects/hemorrhage-classification/stage_2_train_sorted_nifti_pruned\"\n",
    "\n",
    "# Initialize LoadImage transform to load NIFTI images\n",
    "load_image = LoadImage(image_only=True)\n",
    "\n",
    "# Initialize empty list for valid files\n",
    "train_files = []\n",
    "\n",
    "# Loop through subfolders starting with 'ID_'\n",
    "for folder in os.listdir(data_root):\n",
    "    folder_path = os.path.join(data_root, folder)\n",
    "    if os.path.isdir(folder_path) and folder.startswith(\"ID_\"):  # Process only valid folders\n",
    "        try:\n",
    "            # Find the NIfTI file and label file in the folder (ignore 'Eq' files)\n",
    "            image_file = [f for f in os.listdir(folder_path) if f.endswith(\".nii.gz\") and \"Eq\" not in f][0]\n",
    "            label_file = [f for f in os.listdir(folder_path) if f.endswith(\".csv\")][0]\n",
    "\n",
    "            # Full paths to image and label\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            label_path = os.path.join(folder_path, label_file)\n",
    "\n",
    "            # Load the image and check its shape\n",
    "            img = load_image(image_path)\n",
    "            if img.shape[0] != 6:  # Skip images with 6 channels\n",
    "                # Parse the labels CSV and convert to numerical format\n",
    "                df = pd.read_csv(label_path)\n",
    "                # Get the 'any' column value as the label\n",
    "                label = int(df.loc[df[\"hemorrhage_type\"] == \"any\", \"label\"].values[0])\n",
    "                train_files.append({\"image\": image_path, \"label\": label})\n",
    "            else:\n",
    "                print(f\"Skipping image with invalid shape: {img.shape}, path: {image_path}\")\n",
    "\n",
    "        except IndexError:\n",
    "            print(f\"Missing NIfTI or CSV file in folder: {folder_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing folder {folder_path}: {e}\")\n",
    "\n",
    "print(f\"Total valid files: {len(train_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0404e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(label):\n",
    "    label_mapping = {\n",
    "        \"intraparenchymal\": 0,\n",
    "        \"intraventricular\": 1,\n",
    "        \"subarachnoid\": 2,\n",
    "        \"subdural\": 3,\n",
    "        \"epidural\": 4,\n",
    "        \"no_hemorrhage\": 5\n",
    "    }\n",
    "    # Safely map label or raise an error for debugging\n",
    "    if label not in label_mapping:\n",
    "        raise ValueError(f\"Unexpected label: {label}\")\n",
    "    return label_mapping[label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02e616eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 2648\n",
      "Validation samples: 567\n",
      "Test samples: 568\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train (70%), validation (15%), and test (15%)\n",
    "train_files, test_val_files = train_test_split(train_files, test_size=0.3, random_state=42)\n",
    "val_files, test_files = train_test_split(test_val_files, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(train_files)}\")\n",
    "print(f\"Validation samples: {len(val_files)}\")\n",
    "print(f\"Test samples: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "409bf549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from monai.transforms import MapTransform\n",
    "\n",
    "# Custom transform to enforce 3 channels\n",
    "class Ensure3ChannelsD(MapTransform):\n",
    "    def __init__(self, keys):\n",
    "        super().__init__(keys)\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        for key in self.keys:\n",
    "            image = data[key]\n",
    "            if image.shape[0] == 6:  # If 6 channels, take the first 3 channels\n",
    "                image = image[:3, ...]\n",
    "            elif image.shape[0] == 1:  # If single channel, repeat it 3 times\n",
    "                image = torch.cat([image] * 3, dim=0)\n",
    "            elif image.shape[0] > 3:  # In any other case with >3 channels, truncate to 3\n",
    "                image = image[:3, ...]\n",
    "            elif image.shape[0] < 3:  # If less than 3 channels, repeat to reach 3\n",
    "                image = torch.cat([image] * 3, dim=0)[:3, ...]\n",
    "            data[key] = image\n",
    "        return data\n",
    "\n",
    "class SkipInvalidScansD(MapTransform):\n",
    "    \"\"\"\n",
    "    Custom transform to skip scans with invalid channels (e.g., 6 channels).\n",
    "    \"\"\"\n",
    "    def __init__(self, keys):\n",
    "        super().__init__(keys)\n",
    "\n",
    "    def __call__(self, data):\n",
    "        for key in self.keys:\n",
    "            image = data[key]\n",
    "            if image.shape[0] == 6:  # Skip this image\n",
    "                raise ValueError(f\"Invalid image with shape {image.shape}, skipping.\")\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "299226c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.data import CacheDataset, DataLoader\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImageD, EnsureChannelFirstD, Resized, ScaleIntensityD, ToTensorD, LambdaD, RepeatChannelD, CastToTypeD\n",
    ")\n",
    "\n",
    "# Training Transforms\n",
    "train_transforms = Compose([\n",
    "    LoadImageD(keys=[\"image\"]),\n",
    "    EnsureChannelFirstD(keys=[\"image\"]),\n",
    "    RepeatChannelD(keys=[\"image\"], repeats=3),\n",
    "    ScaleIntensityD(keys=[\"image\"]),\n",
    "    ToTensorD(keys=[\"image\", \"label\"])             # Convert both image and label to Tensor\n",
    "])\n",
    "\n",
    "# Validation Transforms\n",
    "val_transforms = Compose([\n",
    "    LoadImageD(keys=[\"image\"]),\n",
    "    EnsureChannelFirstD(keys=[\"image\"]),\n",
    "    RepeatChannelD(keys=[\"image\"], repeats=3),\n",
    "    ScaleIntensityD(keys=[\"image\"]),\n",
    "    ToTensorD(keys=[\"image\", \"label\"])\n",
    "])\n",
    "\n",
    "# Test Transforms\n",
    "test_transforms = Compose([\n",
    "    LoadImageD(keys=[\"image\"]),\n",
    "    EnsureChannelFirstD(keys=[\"image\"]),\n",
    "    RepeatChannelD(keys=[\"image\"], repeats=3),\n",
    "    ScaleIntensityD(keys=[\"image\"]),\n",
    "    ToTensorD(keys=[\"image\", \"label\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdf4a5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0,  Type: <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "for sample in train_files:\n",
    "    print(f\"Label: {sample['label']},  Type: {type(sample['label'])}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a04fd54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  50%|████▉     | 1052/2118 [05:48<06:49,  2.61it/s]"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_ds = CacheDataset(train_files, transform=train_transforms, cache_rate=0.8)\n",
    "val_ds = CacheDataset(val_files, transform=train_transforms, cache_rate=0.8)\n",
    "test_ds = CacheDataset(test_files, transform=train_transforms, cache_rate=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832ab05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in train_ds:\n",
    "    if int(sample[\"image\"].shape[0]) == 6:\n",
    "        print(\"AHHHH\")\n",
    "#     print(sample[\"image\"].shape)  # Should print [3, 128, 128, 128]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5cfd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.data import pad_list_data_collate\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, collate_fn=pad_list_data_collate)\n",
    "val_loader = DataLoader(val_ds, batch_size=2, shuffle=False, collate_fn=pad_list_data_collate)\n",
    "test_loader = DataLoader(test_ds, batch_size=2, shuffle=False, collate_fn=pad_list_data_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda52d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import ViT\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Updated ViT configuration for MONAI 1.4.0\n",
    "model = ViT(\n",
    "    in_channels=3,                   # Input image has 3 channels\n",
    "    img_size=(128, 128, 128),        # Input image size\n",
    "    patch_size=(16, 16, 16),         # Patch size for splitting the image\n",
    "    num_layers=24,                   # 24 transformer blocks\n",
    "    classification=True,             # Enable classification\n",
    "    num_classes=5,                   # Number of output classes\n",
    "    spatial_dims=3,                  # 3D input data\n",
    "    hidden_size=768,                 # Transformer hidden size\n",
    "    mlp_dim=3072,                    # MLP dimension\n",
    "    num_heads=12                     # Number of attention heads\n",
    ").to(device)\n",
    "\n",
    "# model = ViT(\n",
    "#         in_channels=3,\n",
    "#         img_size=(128,128,128),\n",
    "#         proj_type='conv',\n",
    "#         pos_embed_type='sincos',\n",
    "#         classification=True\n",
    "# ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960cd68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "accuracy_metric = Accuracy(task=\"multiclass\", num_classes=5)  # Adjust num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c92b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model.train()\n",
    "max_epochs = 10\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{max_epochs}\"):\n",
    "        inputs, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
    "        \n",
    "        # Ensure labels are a Tensor\n",
    "        if isinstance(labels, tuple):\n",
    "            labels = labels[0]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Fix model output\n",
    "        if isinstance(outputs, tuple):\n",
    "            outputs = outputs[0]\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}, Train Loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for val_batch in val_loader:\n",
    "            val_inputs, val_labels = val_batch[\"image\"].to(device), val_batch[\"label\"].to(device)\n",
    "\n",
    "            # Ensure labels are Tensor\n",
    "            if isinstance(val_labels, tuple):\n",
    "                val_labels = val_labels[0]\n",
    "\n",
    "            val_outputs = model(val_inputs)\n",
    "\n",
    "            # Fix model output\n",
    "            if isinstance(val_outputs, tuple):\n",
    "                val_outputs = val_outputs[0]\n",
    "\n",
    "            val_loss += loss_function(val_outputs, val_labels).item()\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f\"Epoch {epoch + 1}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"Saved best model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cd65d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"vision_transformer_ct_classifier.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22a19ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
